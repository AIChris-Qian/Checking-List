# 机器学习
  by Chen Qian

------------------------------


**1. `[ 特征工程 ]`**    
------------------------------

#### 01 特征归一化

  Q：为什么需要对数值类型的特征做归一化？
     
     线性函数归一化：   X_norm = (X - X_min) / (X_max - X_min)
     零均值归一化：    Z = (X - μ) / σ
     学习率相同的情况下，更新速度不同。

#### 02 类型型特征

   Q：在对数据进行预处理时，应该怎么样处理类别型特征？
    
     (1) 序号编码：高 / 中 / 低   3 / 2 / 1
     (2) 独热编码：血型 (A,B,AB,O) A：(1,0,0,0) B：(0,1,0,0) AB：(0,0,1,0) O：(0,0,0,1) 
     (3) 二进制编码：每个类别赋予一个ID，然后转化为二进制 (维度少于独热编码，节省空间)
   

#### 03 高维组合特征的处理

   Q：什么是组合特征？如何处理高维组合特征？
      
      高阶组合特征：为了提高拟合能力，把一阶离散特征两两组合。
      组合特征 <Xi,Xj> 维度 m * n 太大，使用 k 维的低维向量(k<<m,k<<n) 
      参数规模：m * k + n * k  (矩阵分解)

#### 04 组合特征

   Q：怎样有效地找到组合特征？
       
       决策树： 根据原始输入特征和标签构造决策树。
       GBDT：  在之前构建的决策树残差上构造下一棵决策树。


------------------------------


**2. `[ 模型评估 ]`**    
------------------------------

                   预测为正       预测为反
      实际为正    TP (真正例)    FN (假反例)
      实际为反    FP (假正例)    TN (真反例)


#### 01 评估指标的局限性

   Q：准确率的局限性
      
      准确率 (Accuracy) = (TP + TN) / (TP + FN + FP + TN)
      
      正负样本比 = 1 : 99     把所有样本预测为负样本准确率 99%
      不同类别的样本比例不均衡，占比大的类别会影响准确率。
      

   Q：精确率与召回率的权衡
      
      精确率 (Precision) = TP / (TP + FP)                            排序模型：TOP N 返回的结果被判定为正样本，计算前 N 位置上的精确率和召回率
      召回率 (Recall) = TP / (TP + FN)                               
      
      绘制 P - R 曲线，横轴是召回率，纵轴是精确率。                     F1 score：精确率和召回率的调和平均数    1/F1 = 1/2 * (1/P + 1/R) 
      确定阈值，大于该阈值的判定为正样本，小于该阈值的判定为负样本。
      通过把阈值从高到低移动生成 P - R 曲线。原点附近阈值最大。
      
   
   Q：平均根误差的意外 
      
      RMSE (均方根误差) = √￣(∑(yi - yi~)^2/n)     MSE (均方误差) = ∑(yi - yi~)^2/n        yi：真实值    yi~：预测值    n：样本个数
      
      95% 的区间误差小于 1%，RMSE很差，可能由于其余 5% 区间存在严重的离散点
      解决方法      (1) 如果离群点是噪声点，数据预处理把噪声过滤
                   (2) 如果离群点不是噪声点，进一步提升模型预测能力
                   (3) 找更合适的指标来评估模型：  MAPE (平均绝对百分比误差) = ∑|(yi - yi~) / yi| * 100/n
                                                 把每个点的误差进行归一化，降低离群点带来的影响
   

#### 02 ROC曲线

#### 03 余弦距离的应用

#### 04 AB测试的陷阱

#### 05 模型评估的方法

#### 06 超参数调优

#### 07 过拟合与欠拟合



------------------------------


**3. `[ 经典算法 ]`**    
------------------------------

#### 01 支持向量机

#### 02 逻辑回归

#### 03 决策树



------------------------------


**4. `[ 降维 ]`**    
------------------------------

#### 01 PCA最大方差理论


------------------------------


**5. `[ 非监督学习 ]`**    
------------------------------

#### 01 k均值聚类


------------------------------


**6. `[ 概率图模型 ]`**    
------------------------------

#### 01 概率图模型的联合概率分布

#### 02 概率图表示

#### 03 生成式模型与判别式模型



------------------------------


**7. `[ 优化算法 ]`**    
------------------------------

#### 01 有监督学习的损失函数

#### 02 机器学习中的优化问题

#### 03 经典优化算法

#### 04 随机梯度下降法

#### 05 L1正则化与稀疏性



------------------------------



**8. `[ 前向神经网络 ]`**    
------------------------------

#### 01 深度神经网络中的激活函数

#### 02 多层感知机的反向传播算法

#### 03 神经网络训练技巧



------------------------------



**9. `[ 集成学习 ]`**    
------------------------------

#### 01 集成学习的种类

#### 02 集成学习的步骤和例子

#### 03 基分类器

#### 04 偏差和方差

#### 05 梯度提升决策树

#### 06 XGBoost 与 GBDT 的联系与区别
