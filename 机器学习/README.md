# 机器学习
  by Chen Qian

------------------------------


**1. `[ 特征工程 ]`**    
------------------------------

#### 01 特征归一化

  Q：为什么需要对数值类型的特征做归一化？
     
     线性函数归一化：   X_norm = (X - X_min) / (X_max - X_min)
     零均值归一化：    Z = (X - μ) / σ
     学习率相同的情况下，更新速度不同。

#### 02 类型型特征

   Q：在对数据进行预处理时，应该怎么样处理类别型特征？
    
     (1) 序号编码：高 / 中 / 低   3 / 2 / 1
     (2) 独热编码：血型 (A,B,AB,O) A：(1,0,0,0) B：(0,1,0,0) AB：(0,0,1,0) O：(0,0,0,1) 
     (3) 二进制编码：每个类别赋予一个ID，然后转化为二进制 (维度少于独热编码，节省空间)
   

#### 03 高维组合特征的处理

  Q：什么是组合特征？如何处理高维组合特征？
      
     高阶组合特征：为了提高拟合能力，把一阶离散特征两两组合。
     组合特征 <Xi,Xj> 维度 m * n 太大，使用 k 维的低维向量(k<<m,k<<n) 
     参数规模：m * k + n * k  (矩阵分解)

#### 04 组合特征

   Q：怎样有效地找到组合特征？
       
     决策树： 根据原始输入特征和标签构造决策树。
     GBDT：  在之前构建的决策树残差上构造下一棵决策树。


------------------------------


**2. `[ 模型评估 ]`**    
------------------------------

                  预测为正       预测为反
     实际为正    TP (真正例)    FN (假反例)
     实际为反    FP (假正例)    TN (真反例)


#### 01 评估指标的局限性

   Q：准确率的局限性
      
     准确率 (Accuracy) = (TP + TN) / (TP + FN + FP + TN)
      
     正负样本比 = 1 : 99     把所有样本预测为负样本准确率 99%
     不同类别的样本比例不均衡，占比大的类别会影响准确率。
      

   Q：精确率与召回率的权衡
      
     精确率 (Precision) = TP / (TP + FP)                            排序模型：TOP N 返回的结果被判定为正样本，计算前 N 位置上的精确率和召回率
     召回率 (Recall) = TP / (TP + FN)                               
      
     绘制 P - R 曲线，横轴是召回率，纵轴是精确率。                     F1 score：精确率和召回率的调和平均数    1/F1 = 1/2 * (1/P + 1/R) 
     确定阈值，大于该阈值的判定为正样本，小于该阈值的判定为负样本。
     通过把阈值从高到低移动生成 P - R 曲线。原点附近阈值最大。
      
   
   Q：平均根误差的意外 
      
     RMSE (均方根误差) = √￣(∑(yi - yi~)^2/n)     MSE (均方误差) = ∑(yi - yi~)^2/n        yi：真实值    yi~：预测值    n：样本个数
      
     95% 的区间误差小于 1%，RMSE很差，可能由于其余 5% 区间存在严重的离散点
     解决方法      (1) 如果离群点是噪声点，数据预处理把噪声过滤
                  (2) 如果离群点不是噪声点，进一步提升模型预测能力
                  (3) 找更合适的指标来评估模型：  MAPE (平均绝对百分比误差) = ∑|(yi - yi~) / yi| * 100/n
                                                把每个点的误差进行归一化，降低离群点带来的影响
   

#### 02 ROC曲线

   Q：什么是ROC曲线？
      
     受试者工作特征曲线，横坐标为假阳性率，纵坐标为真阳性率
      
     真阳性率 (TPR) = TP / (TP + FN)                           
     假阳性率 (FPR) = FP / (FP + TN)      

   Q：如何绘制ROC曲线？
      
     不断移动分类器的截断点来生成曲线上的一些关键点。
     指定阈值，大于该阈值判为正例，小于该阈值判为负例。截断点就是阈值。
     从最高得分开始 (ROC曲线零点)，逐渐调整到最低分。
      
     简便方法：从零点开始，每遇到一个正样本就沿纵轴方向，每遇到一个负样本就沿横轴方向。
      

   Q：如何计算AUC？
      
     ROC曲线下面积大小，量化ROC曲线衡量出的模型性能。
     计算AUC，沿着ROC横轴做积分。AUC取值在 0.5 ~ 1 之间。
     AUC越大，分类性能越好。


   Q：ROC曲线相比 P - R 曲线有什么特点？
      
     当正负样本的分布发生变化时，ROC曲线的形状能保持基本不变，P - R 曲线会发生剧烈的变化。
     ROC曲线能降低不同测试集带来的干扰，更客观地衡量模型的性能。
     实际问题中，正负样本数量往往不均衡。ROC使用场景：排序 / 推荐 / 广告。
      

#### 03 余弦距离的应用
   
     余弦相似度：   两个特征向量之间的相似性。取值范围为 [-1,1]，相同的两个向量之间相似度为1。
     余弦距离：    1 - 余弦相似度，取值范围为 [0,2]，相同的两个向量余弦距离为0。
    

   Q：为什么在一些场景要使用余弦相似度而不是欧氏距离？
     
     余弦相似度： cos(A,B) = (A * B) / (|A| * |B|)
      
     余弦相似度在高维下，保持" 相同时为1，正交时为0，相反时为-1"。
     欧氏距离在高维情况下范围不确定。
      
     模长经过归一化，欧氏距离与余弦距离的关系：|A - B| = √￣(2(1 - cos(A,B)))
      
     欧式距离：数值上的绝对差异    (用户活跃度：登录次数 / 平均观看时长)
     余弦距离：方向上的相对差异    (用户偏好)

   
   
   Q：余弦距离是否一个严格定义的距离？
     
     不是
     
     距离：每一对元素确定一个实数，使得 (正定性 / 对称性 / 三角不等式) 成立，这个实数称为距离。
      
     余弦距离：dist(A,B) = 1 - cos(A,B)
          (1)  正定性：cos(A,B) ≤ 1，dist(A,B) ≥ 0  成立
          (2)  对称性：dist(A,B) = 1 - cos(A,B) = 1 - cos(B,A) = dist(B,A)  成立
          (3)  三角不等式：A = (1,0) B = (1,1) C = (0,1) 
                          dist(A,B) + dist(B,C) < dist(A,C)  不成立
      
   

   
#### 04 AB测试的陷阱

   Q：对模型进行充分的离线评估后，为什么还要进行在线AB测试？


     (1) 离线评估无法完全消除过拟合的影响
     (2) 离线评估是在理想环境下，没有考虑数据丢失的情况
     (3) 某些商业指标在离线评估中无法计算
          离线评估关注：  ROC曲线 / P — R 曲线
          线上评估关注：  用户点击率 / 留存时长 / PV访问量


   Q：如何进行线上AB测试？
        
     用户分成实验组和对照组   实验组：新模型    对照组：旧模型


   Q：如何划分实验组和对照组？
        
     基于设备号 / 用户ID尾号进行分组 (奇数分为实验组，偶数分为对照组)

#### 05 模型评估的方法


   Q：在模型评估过程中，有哪些主要的验证方法？优缺点是什么？
        
     (1)  Holdout 检验：70% 训练集，模型训练。30% 验证集，模型验证。
                       缺点：验证集上计算出来的评估指标与原始分组有关
                       
     (2)  交叉检验：
          k-fold 交叉检验：样本分成 k 个大小相等的样本子集，依次遍历这 k 个子集。
                          当前子集作为验证集，其余子集作为训练集。最后把 k 次评估指标平均值作为最终的评估指标。
          留 p 验证：样本总数为 n，依次对 n 个样本进行遍历。每次留下 p 个样本作为验证集，其余样本作为测试集。 C(n,p)
                    时间花费远大于留一验证。
     
     (3)  自助法：
          样本数为 n，进行 n 次有放回的随机抽样，得到大小为 n 的训练集。n 次采样中，没有被抽出的样本作为验证集。(适合小样本)
          
          
                    
   Q：在自助法的采样过程中，对 n 个样本进行 n 次自助抽样，当 `n → ∞`，有多少数据从未被选过？
        
     (1 - 1/n)^n  lim(n → ∞)(1 - 1/n)^n = 1/e ≈ 0.368 
       
       
#### 06 超参数调优

   Q：数据集分为哪几类？
     
     数据集：训练集 / 验证集 / 测试集
            训练集：总样本的 70% - 80%，用于模型训练。
            验证集：不参与模型训练，对超参数进行选择。
            测试集：结果未知，利用训练模型输出。
            
     模型上线后，输出测试集上的结果，与实际结果进行对比。
     测试集后续转化为训练集 / 验证集，实现模型的不断迭代与优化。


   Q：简述参数与超参数之间的区别？

     参数：通过模型对训练集的拟合获得的。
     超参数：在训练前人为给出超参数。通过验证集验证。
     
     调参：调整超参数
   

   Q：超参数有哪些调优方法？

     网格搜索 / 随机搜索 / 贝叶斯优化算法

#### 07 过拟合与欠拟合


   Q：在模型评估中，过拟合和欠拟合具体指什么现象？

     过拟合：模型在训练集上表现很好，在测试集上表现很差。
            模型过于复杂，把噪声数据特征也学习了，导致模型泛化能力下降。
            
     欠拟合：模型在训练集和测试集上表现都不好的情况。
            模型过于简单不能很好地拟合数据。



   Q：能否说说几种降低过拟合和欠拟合风险的方法？

     (1) 降低过拟合的方法
         更多训练数据，学习更多特征，减少噪声的影响。
         降低模型复杂度，避免模型拟合过多的噪声。
         正则化方法。加入损失函数，避免过拟合风险。
         集成学习方法。多个模型集成在一起，降低单一模型的过拟合风险。

     (2) 降低欠拟合的方法
         增加新特征，特征不足时容易出现欠拟合。
         增加模型复杂度，增加复杂度提升模型的拟合能力。



------------------------------


**3. `[ 经典算法 ]`**    
------------------------------

#### 01 支持向量机

   Q：支持向量机原理？
     
     线性可分：存在一个超平面可以将训练样本正确分类
     
     找到一个最大软间隔的超平面，使得训练样本可以正确分类。
     如果原始空间不存在这样一个超平面，可以使用核函数把样本从原始空间映射到一个更高维的空间，使得样本在这个空间里线性可分。
     
   Q：常见核函数？
     
     线性核 / 多项核 / 高斯核 / 拉普拉斯核 / Sigmoid核


#### 02 逻辑回归

   Q：逻辑回归推导？
     
     似然估计相乘，然后取对数
     
   Q：逻辑回归相比线性回归，有何异同？
     
     逻辑回归：分类问题，因变量为离散，广义线性模型因变量 y 服从二元分布。
     线性回归：预测问题，因变量为连续，最小二乘法求解因变量 y 服从正态分布。
     
     相同：两者都使用极大近似估计来对训练样本建模。求解超参数时都使用梯度下降。


   Q：当使用逻辑回归处理多标签的分类问题时，有哪些常用方法？
     

     (1) 一个样本对应一个标签，概率服从几何分布，使用 softmax 进行分类。
     
     (2) 一个样本对应多个标签，训练 k 个二分类的逻辑回归分类器。
         第 i 个分类器：标签是否归为第 i 类。

#### 03 决策树
     
     决策树 (集成学习) → 随机森林 / 梯度提升决策树
     决策树的生成：特征选择 / 树的结构 / 树的剪枝

   Q：决策树有哪些常用的启发函数？
     
     ID3 / C4.5 / CART
     
     (1) ID3 - 最大信息增益
     (2) C4.5 - 最大信息增益比
     (3) CART - 最小基尼指数
     
     ID3：会倾向于选择取值较多的特征，特征越多，信息增益越大。
     C4.5：ID3优化，对取值较多的特征进行惩罚，避免ID3过拟合。
     
     离散型变量：ID3           连续性变量：C4.5 / CART
     分类任务：ID3 / C4.5      分类 / 回归任务：CART
     
     
 
   Q：如何对决策树进行剪枝？
     
     完全生长的决策树 → 过拟合   通过剪枝，提升模型的泛化能力。
     剪枝：预剪枝 / 后剪枝
     
     (1) 预剪枝：生成决策树的过程中提前停止树的增长   (容易欠拟合)
     (2) 后剪枝：已生成的过拟合决策树进行剪枝         (有更强的泛化能力，时间更长)
     
         
     
         
------------------------------


**4. `[ 降维 ]`**    
------------------------------
     
     高维空间包含很多噪声，用降维方式寻找数据内部的特性。
     
#### 01 PCA最大方差理论

         
   Q：定义主成分？如何设计目标函数？如何针对 PCA 问题进行求解？
   
     主轴上数据分布越分散，数据在这个方向方差越大。
     PCA目标：最大化投影方差，数据在主轴上的投影的方差最大。
     
     PCA求解方法
     (1) 样本数据中心化处理                                        {x1,x2,.....} = {v1 - μ,v2 - μ,......}
     (2) 样本协方差矩阵                                            1/n * ∑(xi * xi^T)
     (3) 特征值求解，特征值从大到小排列                             {λ1,λ2,λ3,......}
     (4) 特征值前 d 大对应的特征向量 w1,W2,...., n 维映射到 d 维     xi~ = [w1^T * xi,w2^T * xi,.....,wd^T * xi]^T 
     

 
------------------------------


**5. `[ 非监督学习 ]`**    
------------------------------

#### 01 k均值聚类

   Q：阐述监督学习和非监督学习的区别？
      
     监督学习：训练集既有特征，又有标签。测试集通过训练获得标签。
              标签连续：预测      线性回归 / 神经网络 / 时间序列
              标签离散：分类      逻辑回归 / 支持向量机 / 决策树
              
     非监督学习：训练集只有特征，没有标签。
                聚类：把样本分成若干类      k均值 / EM算法
                降维：高维度数据           主成分分析
                

   Q：参数模型和非参数模型的区别和优缺点？
      
     参数模型：训练前确定目标函数          逻辑回归 / 线性回归 / 朴素贝叶斯
     非参数模型：训练前没有确定目标函数    主成分分析 / 决策树
     
     参数优点：模型训练快，数据量小
         缺点：需要提前对目标函数做假设。复杂度低，容易欠拟合
              
     非参数优点：无需做假设，训练模型能逼近任意复杂的真实模型
           缺点：模型复杂计算量大。
           
   
   Q：简述k均值算法的具体步骤？
      
     通过迭代方法寻找 k 个簇的一种划分方案，使得聚类结果的代价函数最小。
     
     (1) 数据预处理：归一化 / 离群点处理
     (2) 随机选取 k 个簇中心
     (3) 定义代价函数
     (4) 重复下面过程直到代价函数收敛
                                    对于每一个样本，将其分配到距离最近的簇
                                    对于每一个类簇，重新计算该类簇的中心
                                    
     k均值算法迭代，代价函数没有收敛时，固定簇中心，更新每个样本所属的簇类别。然后固定簇类别，更新簇中心。直到代价函数收敛。


   
   Q：k均值算法的优缺点是什么？如何对其调优？
      
     缺点：通常是局部最优解 / 无法解决数据簇分布差异大的情况
     优点：k均值算法是高效的，复杂度时线性的。



------------------------------


**6. `[ 概率图模型 ]`**    
------------------------------

#### 01 概率图模型的联合概率分布

#### 02 概率图表示

#### 03 生成式模型与判别式模型



------------------------------


**7. `[ 优化算法 ]`**    
------------------------------

#### 01 有监督学习的损失函数

#### 02 机器学习中的优化问题

#### 03 经典优化算法

#### 04 随机梯度下降法

#### 05 L1正则化与稀疏性



------------------------------



**8. `[ 前向神经网络 ]`**    
------------------------------

#### 01 深度神经网络中的激活函数

#### 02 多层感知机的反向传播算法

#### 03 神经网络训练技巧



------------------------------



**9. `[ 集成学习 ]`**    
------------------------------

#### 01 集成学习的种类

#### 02 集成学习的步骤和例子

#### 03 基分类器

#### 04 偏差和方差

#### 05 梯度提升决策树

#### 06 XGBoost 与 GBDT 的联系与区别
