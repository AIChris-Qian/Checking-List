# 机器学习
  by Chen Qian

------------------------------


**1. `[ 特征工程 ]`**    
------------------------------

#### 01 特征归一化

  Q：为什么需要对数值类型的特征做归一化？
     
     线性函数归一化：   X_norm = (X - X_min) / (X_max - X_min)
     零均值归一化：    Z = (X - μ) / σ
     学习率相同的情况下，更新速度不同。

#### 02 类型型特征

   Q：在对数据进行预处理时，应该怎么样处理类别型特征？
    
     (1) 序号编码：高 / 中 / 低   3 / 2 / 1
     (2) 独热编码：血型 (A,B,AB,O) A：(1,0,0,0) B：(0,1,0,0) AB：(0,0,1,0) O：(0,0,0,1) 
     (3) 二进制编码：每个类别赋予一个ID，然后转化为二进制 (维度少于独热编码，节省空间)
   

#### 03 高维组合特征的处理

   Q：什么是组合特征？如何处理高维组合特征？
      
      高阶组合特征：为了提高拟合能力，把一阶离散特征两两组合。
      组合特征 <Xi,Xj> 维度 m * n 太大，使用 k 维的低维向量(k<<m,k<<n) 
      参数规模：m * k + n * k  (矩阵分解)

#### 04 组合特征

   Q：怎样有效地找到组合特征？
       
       决策树： 根据原始输入特征和标签构造决策树。
       GBDT：  在之前构建的决策树残差上构造下一棵决策树。


------------------------------


**2. `[ 模型评估 ]`**    
------------------------------

#### 01 评估指标的局限性

#### 02 ROC曲线

#### 03 余弦距离的应用

#### 04 AB测试的陷阱

#### 05 模型评估的方法

#### 06 超参数调优

#### 07 过拟合与欠拟合



------------------------------


**3. `[ 经典算法 ]`**    
------------------------------

#### 01 支持向量机

#### 02 逻辑回归

#### 03 决策树



------------------------------


**4. `[ 降维 ]`**    
------------------------------

#### 01 PCA最大方差理论


------------------------------


**5. `[ 非监督学习 ]`**    
------------------------------

#### 01 k均值聚类


------------------------------


**6. `[ 概率图模型 ]`**    
------------------------------

#### 01 概率图模型的联合概率分布

#### 02 概率图表示

#### 03 生成式模型与判别式模型



------------------------------


**7. `[ 优化算法 ]`**    
------------------------------

#### 01 有监督学习的损失函数

#### 02 机器学习中的优化问题

#### 03 经典优化算法

#### 04 随机梯度下降法

#### 05 L1正则化与稀疏性



------------------------------



**8. `[ 前向神经网络 ]`**    
------------------------------

#### 01 深度神经网络中的激活函数

#### 02 多层感知机的反向传播算法

#### 03 神经网络训练技巧



------------------------------



**9. `[ 集成学习 ]`**    
------------------------------

#### 01 集成学习的种类

#### 02 集成学习的步骤和例子

#### 03 基分类器

#### 04 偏差和方差

#### 05 梯度提升决策树

#### 06 XGBoost 与 GBDT 的联系与区别
