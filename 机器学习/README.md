# 机器学习
  by Chen Qian

------------------------------


**1. `[ 特征工程 ]`**    
------------------------------

#### 01 特征归一化

  Q：为什么需要对数值类型的特征做归一化？
     
     线性函数归一化：   X_norm = (X - X_min) / (X_max - X_min)
     零均值归一化：    Z = (X - μ) / σ
     学习率相同的情况下，更新速度不同。

#### 02 类型型特征

   Q：在对数据进行预处理时，应该怎么样处理类别型特征？
    
     (1) 序号编码：高 / 中 / 低   3 / 2 / 1
     (2) 独热编码：血型 (A,B,AB,O) A：(1,0,0,0) B：(0,1,0,0) AB：(0,0,1,0) O：(0,0,0,1) 
     (3) 二进制编码：每个类别赋予一个ID，然后转化为二进制 (维度少于独热编码，节省空间)
   

#### 03 高维组合特征的处理

  Q：什么是组合特征？如何处理高维组合特征？
      
     高阶组合特征：为了提高拟合能力，把一阶离散特征两两组合。
     组合特征 <Xi,Xj> 维度 m * n 太大，使用 k 维的低维向量(k<<m,k<<n) 
     参数规模：m * k + n * k  (矩阵分解)

#### 04 组合特征

   Q：怎样有效地找到组合特征？
       
     决策树： 根据原始输入特征和标签构造决策树。
     GBDT：  在之前构建的决策树残差上构造下一棵决策树。


------------------------------


**2. `[ 模型评估 ]`**    
------------------------------

                  预测为正       预测为反
     实际为正    TP (真正例)    FN (假反例)
     实际为反    FP (假正例)    TN (真反例)


#### 01 评估指标的局限性

   Q：准确率的局限性
      
     准确率 (Accuracy) = (TP + TN) / (TP + FN + FP + TN)
      
     正负样本比 = 1 : 99     把所有样本预测为负样本准确率 99%
     不同类别的样本比例不均衡，占比大的类别会影响准确率。
      

   Q：精确率与召回率的权衡
      
     精确率 (Precision) = TP / (TP + FP)                            排序模型：TOP N 返回的结果被判定为正样本，计算前 N 位置上的精确率和召回率
     召回率 (Recall) = TP / (TP + FN)                               
      
     绘制 P - R 曲线，横轴是召回率，纵轴是精确率。                     F1 score：精确率和召回率的调和平均数    1/F1 = 1/2 * (1/P + 1/R) 
     确定阈值，大于该阈值的判定为正样本，小于该阈值的判定为负样本。
     通过把阈值从高到低移动生成 P - R 曲线。原点附近阈值最大。
      
   
   Q：平均根误差的意外 
      
     RMSE (均方根误差) = √￣(∑(yi - yi~)^2/n)     MSE (均方误差) = ∑(yi - yi~)^2/n        yi：真实值    yi~：预测值    n：样本个数
      
     95% 的区间误差小于 1%，RMSE很差，可能由于其余 5% 区间存在严重的离散点
     解决方法      (1) 如果离群点是噪声点，数据预处理把噪声过滤
                  (2) 如果离群点不是噪声点，进一步提升模型预测能力
                  (3) 找更合适的指标来评估模型：  MAPE (平均绝对百分比误差) = ∑|(yi - yi~) / yi| * 100/n
                                                把每个点的误差进行归一化，降低离群点带来的影响
   

#### 02 ROC曲线

   Q：什么是ROC曲线？
      
     受试者工作特征曲线，横坐标为假阳性率，纵坐标为真阳性率
      
     真阳性率 (TPR) = TP / (TP + FN)                           
     假阳性率 (FPR) = FP / (FP + TN)      

   Q：如何绘制ROC曲线？
      
     不断移动分类器的截断点来生成曲线上的一些关键点。
     指定阈值，大于该阈值判为正例，小于该阈值判为负例。截断点就是阈值。
     从最高得分开始 (ROC曲线零点)，逐渐调整到最低分。
      
     简便方法：从零点开始，每遇到一个正样本就沿纵轴方向，每遇到一个负样本就沿横轴方向。
      

   Q：如何计算AUC？
      
     ROC曲线下面积大小，量化ROC曲线衡量出的模型性能。
     计算AUC，沿着ROC横轴做积分。AUC取值在 0.5 ~ 1 之间。
     AUC越大，分类性能越好。


   Q：ROC曲线相比 P - R 曲线有什么特点？
      
     当正负样本的分布发生变化时，ROC曲线的形状能保持基本不变，P - R 曲线会发生剧烈的变化。
     ROC曲线能降低不同测试集带来的干扰，更客观地衡量模型的性能。
     实际问题中，正负样本数量往往不均衡。ROC使用场景：排序 / 推荐 / 广告。
      

#### 03 余弦距离的应用
   
     余弦相似度：   两个特征向量之间的相似性。取值范围为 [-1,1]，相同的两个向量之间相似度为1。
     余弦距离：    1 - 余弦相似度，取值范围为 [0,2]，相同的两个向量余弦距离为0。
    

   Q：为什么在一些场景要使用余弦相似度而不是欧氏距离？
     
     余弦相似度： cos(A,B) = (A * B) / (|A| * |B|)
      
     余弦相似度在高维下，保持" 相同时为1，正交时为0，相反时为-1"。
     欧氏距离在高维情况下范围不确定。
      
     模长经过归一化，欧氏距离与余弦距离的关系：|A - B| = √￣(2(1 - cos(A,B)))
      
     欧式距离：数值上的绝对差异    (用户活跃度：登录次数 / 平均观看时长)
     余弦距离：方向上的相对差异    (用户偏好)

   
   
   Q：余弦距离是否一个严格定义的距离？
     
     不是
     
     距离：每一对元素确定一个实数，使得 (正定性 / 对称性 / 三角不等式) 成立，这个实数称为距离。
      
     余弦距离：dist(A,B) = 1 - cos(A,B)
          (1)  正定性：cos(A,B) ≤ 1，dist(A,B) ≥ 0  成立
          (2)  对称性：dist(A,B) = 1 - cos(A,B) = 1 - cos(B,A) = dist(B,A)  成立
          (3)  三角不等式：A = (1,0) B = (1,1) C = (0,1) 
                          dist(A,B) + dist(B,C) < dist(A,C)  不成立
      
   

   
#### 04 AB测试的陷阱

   Q：对模型进行充分的离线评估后，为什么还要进行在线AB测试？


     (1) 离线评估无法完全消除过拟合的影响
     (2) 离线评估是在理想环境下，没有考虑数据丢失的情况
     (3) 某些商业指标在离线评估中无法计算
          离线评估关注：  ROC曲线 / P — R 曲线
          线上评估关注：  用户点击率 / 留存时长 / PV访问量


   Q：如何进行线上AB测试？
        
     用户分成实验组和对照组   实验组：新模型    对照组：旧模型


   Q：如何划分实验组和对照组？
        
     基于设备号 / 用户ID尾号进行分组 (奇数分为实验组，偶数分为对照组)

#### 05 模型评估的方法


   Q：在模型评估过程中，有哪些主要的验证方法？优缺点是什么？
        
     (1)  Holdout 检验：70% 训练集，模型训练。30% 验证集，模型验证。
                       缺点：验证集上计算出来的评估指标与原始分组有关
                       
     (2)  交叉检验：
          k-fold 交叉检验：样本分成 k 个大小相等的样本子集，依次遍历这 k 个子集。
                          当前子集作为验证集，其余子集作为训练集。最后把 k 次评估指标平均值作为最终的评估指标。
          留 p 验证：样本总数为 n，依次对 n 个样本进行遍历。每次留下 p 个样本作为验证集，其余样本作为测试集。 C(n,p)
                    时间花费远大于留一验证。
     
     (3)  自助法：
          样本数为 n，进行 n 次有放回的随机抽样，得到大小为 n 的训练集。n 次采样中，没有被抽出的样本作为验证集。(适合小样本)
          
          
                    
   Q：在自助法的采样过程中，对 n 个样本进行 n 次自助抽样，当 `n → ∞`，有多少数据从未被选过？
        
     (1 - 1/n)^n  lim(n → ∞)(1 - 1/n)^n = 1/e ≈ 0.368 


#### 06 超参数调优

   Q：超参数有哪些调优方法？

     网格搜索 / 随机搜索 / 贝叶斯优化算法

#### 07 过拟合与欠拟合


   Q：在模型评估中，过拟合和欠拟合具体指什么现象？

     过拟合：模型在训练集上表现很好，在测试集上表现很差。
            模型过于复杂，把噪声数据特征也学习了，导致模型泛化能力下降。
            
     欠拟合：模型在训练集和测试集上表现都不好的情况。
            模型过于简单不能很好地拟合数据。



   Q：能否说说几种降低过拟合和欠拟合风险的方法？

     (1) 降低过拟合的方法
         更多训练数据，学习更多特征，减少噪声的影响。
         降低模型复杂度，避免模型拟合过多的噪声。
         正则化方法。加入损失函数，避免过拟合风险。
         集成学习方法。多个模型集成在一起，降低单一模型的过拟合风险。

     (2) 降低欠拟合的方法
         增加新特征，特征不足时容易出现欠拟合。
         增加模型复杂度，增加复杂度提升模型的拟合能力。



------------------------------


**3. `[ 经典算法 ]`**    
------------------------------

#### 01 支持向量机

#### 02 逻辑回归

#### 03 决策树



------------------------------


**4. `[ 降维 ]`**    
------------------------------

#### 01 PCA最大方差理论


------------------------------


**5. `[ 非监督学习 ]`**    
------------------------------

#### 01 k均值聚类


------------------------------


**6. `[ 概率图模型 ]`**    
------------------------------

#### 01 概率图模型的联合概率分布

#### 02 概率图表示

#### 03 生成式模型与判别式模型



------------------------------


**7. `[ 优化算法 ]`**    
------------------------------

#### 01 有监督学习的损失函数

#### 02 机器学习中的优化问题

#### 03 经典优化算法

#### 04 随机梯度下降法

#### 05 L1正则化与稀疏性



------------------------------



**8. `[ 前向神经网络 ]`**    
------------------------------

#### 01 深度神经网络中的激活函数

#### 02 多层感知机的反向传播算法

#### 03 神经网络训练技巧



------------------------------



**9. `[ 集成学习 ]`**    
------------------------------

#### 01 集成学习的种类

#### 02 集成学习的步骤和例子

#### 03 基分类器

#### 04 偏差和方差

#### 05 梯度提升决策树

#### 06 XGBoost 与 GBDT 的联系与区别
